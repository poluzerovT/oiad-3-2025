{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "58996a12",
   "metadata": {},
   "source": [
    "# Insurance Cost Regression\n",
    "\n",
    "Этот ноутбук реализует весь необходимый пайплайн, разбитый на понятные ячейки: подготовка данных, две реализации линейной регрессии (аналитическая и градиентный спуск), добавление регуляризации (Ridge) аналитически и численно, и сравнение моделей по MSE на тесте. Все регрессии реализованы через классы для удобного переиспользования.\n",
    "\n",
    "**Файлы (ожидаются по путям):** `../datasets/insurance_train.csv`, `../datasets/insurance_test.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51f4655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Блок 1: импорты\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Optional, Tuple\n",
    "from dataclasses import dataclass\n",
    "from copy import deepcopy\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720bcdf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Блок 2: загрузка данных\n",
    "train_path = '../datasets/insurance_train.csv'\n",
    "test_path  = '../datasets/insurance_test.csv'\n",
    "\n",
    "try:\n",
    "    df_train = pd.read_csv(train_path)\n",
    "    df_test  = pd.read_csv(test_path)\n",
    "    print('Train shape:', df_train.shape)\n",
    "    print('Test shape :', df_test.shape)\n",
    "except Exception as e:\n",
    "    print('Не удалось загрузить файлы по ожидаемым путям. Ошибка:', e)\n",
    "    print('Проверьте, что файлы существуют и пути правильные.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d1551a4",
   "metadata": {},
   "source": [
    "## 1. Подготовка данных\n",
    "1. Проверка пропусков и выбросов\n",
    "2. Приведение категориальных признаков к числовым\n",
    "3. Парные корреляции признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a355ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Блок 3: Простая проверка пропусков и первичная обработка\n",
    "def basic_eda(df: pd.DataFrame, name: str='data'):\n",
    "    print(f'== {name} ==')\n",
    "    print('shape:', df.shape)\n",
    "    print('\\nПропуски по столбцам:')\n",
    "    print(df.isnull().sum())\n",
    "    print('\\nОписательная статистика (числовые):')\n",
    "    display(df.describe(include='all'))\n",
    "\n",
    "basic_eda(df_train, 'train')\n",
    "basic_eda(df_test, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa7d637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Блок 4: Обработаем категориальные признаки и проверим выбросы\n",
    "def preprocess_basic(df: pd.DataFrame, fit_scaler: Optional[StandardScaler]=None):\n",
    "    df = df.copy()\n",
    "    # Бинарные маппинги\n",
    "    if 'sex' in df.columns:\n",
    "        df['sex'] = df['sex'].map({'male':0, 'female':1})\n",
    "    if 'smoker' in df.columns:\n",
    "        df['smoker'] = df['smoker'].map({'no':0, 'yes':1})\n",
    "    # region -> one-hot если есть\n",
    "    if 'region' in df.columns:\n",
    "        region_dummies = pd.get_dummies(df['region'], prefix='region')\n",
    "        df = pd.concat([df.drop(columns=['region']), region_dummies], axis=1)\n",
    "    # X, y\n",
    "    if 'charges' in df.columns:\n",
    "        y = df['charges'].values.reshape(-1,1)\n",
    "        X = df.drop(columns=['charges']).values.astype(float)\n",
    "    else:\n",
    "        y = None\n",
    "        X = df.values.astype(float)\n",
    "    if fit_scaler is None:\n",
    "        scaler = StandardScaler()\n",
    "        X_scaled = scaler.fit_transform(X)\n",
    "        return X_scaled, y, scaler, df\n",
    "    else:\n",
    "        X_scaled = fit_scaler.transform(X)\n",
    "        return X_scaled, y, fit_scaler, df\n",
    "\n",
    "X_train_scaled, y_train, scaler, df_train_proc = preprocess_basic(df_train)\n",
    "X_test_scaled, y_test, _, df_test_proc = preprocess_basic(df_test, fit_scaler=scaler)\n",
    "\n",
    "print('Processed train shape:', X_train_scaled.shape)\n",
    "print('Processed test shape :', X_test_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "753025f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Блок 5: Проверка выбросов (IQR) и корреляции\n",
    "def detect_outliers_iqr(df, col):\n",
    "    q1 = df[col].quantile(0.25)\n",
    "    q3 = df[col].quantile(0.75)\n",
    "    iqr = q3 - q1\n",
    "    lower = q1 - 1.5 * iqr\n",
    "    upper = q3 + 1.5 * iqr\n",
    "    return df[(df[col] < lower) | (df[col] > upper)][col]\n",
    "\n",
    "numeric_cols = df_train.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print('Числовые столбцы:', numeric_cols)\n",
    "\n",
    "for col in numeric_cols:\n",
    "    out = detect_outliers_iqr(df_train, col)\n",
    "    print(f'{col}: {len(out)} выбросов (IQR)')\n",
    "\n",
    "corr = pd.DataFrame(df_train_proc.select_dtypes(include=[np.number])).corr()\n",
    "if 'charges' in df_train.columns:\n",
    "    corr_with_target = corr['charges'].abs().sort_values(ascending=False)\n",
    "    print('\\nТоп по корреляции с charges:')\n",
    "    display(corr_with_target.head(10))\n",
    "print('\\nЧасть матрицы корреляций:')\n",
    "display(corr.iloc[:8, :8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c247cffd",
   "metadata": {},
   "source": [
    "## 2. Многомерная линейная регрессия\n",
    "Реализуем классы регрессоров: аналитический и через градиентный спуск."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3533a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Блок 6: Базовый регрессор\n",
    "class BaseLinearRegressor:\n",
    "    def __init__(self):\n",
    "        self.w = None\n",
    "        self.fitted = False\n",
    "\n",
    "    def _add_bias(self, X):\n",
    "        return np.hstack([np.ones((X.shape[0], 1)), X])\n",
    "\n",
    "    def predict(self, X):\n",
    "        Xb = self._add_bias(X)\n",
    "        return Xb.dot(self.w).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4b98f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Блок 7: Аналитическая лин. регрессия\n",
    "class LinearAnalytic(BaseLinearRegressor):\n",
    "    def fit(self, X, y):\n",
    "        Xb = self._add_bias(X)\n",
    "        XtX = Xb.T.dot(Xb)\n",
    "        Xty = Xb.T.dot(y)\n",
    "        try:\n",
    "            w = np.linalg.solve(XtX, Xty)\n",
    "        except np.linalg.LinAlgError:\n",
    "            w = np.linalg.pinv(XtX).dot(Xty)\n",
    "        self.w = w.reshape(-1,1)\n",
    "        self.fitted = True\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13db6491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Блок 8: Линейная регрессия (GD)\n",
    "class LinearGD(BaseLinearRegressor):\n",
    "    def __init__(self, lr=1e-2, n_iter=1000, tol=1e-6, verbose=False):\n",
    "        super().__init__()\n",
    "        self.lr = lr\n",
    "        self.n_iter = n_iter\n",
    "        self.tol = tol\n",
    "        self.verbose = verbose\n",
    "        self.loss_history = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        Xb = self._add_bias(X)\n",
    "        n, d = Xb.shape\n",
    "        w = np.zeros((d,1))\n",
    "        prev_loss = np.inf\n",
    "        for it in range(self.n_iter):\n",
    "            preds = Xb.dot(w)\n",
    "            err = preds - y\n",
    "            loss = (err**2).mean()\n",
    "            grad = 2.0 * Xb.T.dot(err) / n\n",
    "            w = w - self.lr * grad\n",
    "            self.loss_history.append(loss)\n",
    "            if self.verbose and it % (self.n_iter//10 + 1) == 0:\n",
    "                print(f'it {it}, loss {loss:.6f}')\n",
    "            if abs(prev_loss - loss) < self.tol:\n",
    "                break\n",
    "            prev_loss = loss\n",
    "        self.w = w\n",
    "        self.fitted = True\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6b70d9",
   "metadata": {},
   "source": [
    "## 3. Добавление регуляризации (Ridge) — аналитически и через GD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451f2bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Блок 9: Ridge аналитически\n",
    "class RidgeAnalytic(BaseLinearRegressor):\n",
    "    def __init__(self, lam=1.0):\n",
    "        super().__init__()\n",
    "        self.lam = lam\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        Xb = self._add_bias(X)\n",
    "        n, d = Xb.shape\n",
    "        L = np.eye(d)\n",
    "        L[0,0] = 0.0\n",
    "        XtX = Xb.T.dot(Xb)\n",
    "        A = XtX + self.lam * L\n",
    "        Xty = Xb.T.dot(y)\n",
    "        try:\n",
    "            w = np.linalg.solve(A, Xty)\n",
    "        except np.linalg.LinAlgError:\n",
    "            w = np.linalg.pinv(A).dot(Xty)\n",
    "        self.w = w.reshape(-1,1)\n",
    "        self.fitted = True\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673a9dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Блок 10: Ridge через GD\n",
    "class RidgeGD(BaseLinearRegressor):\n",
    "    def __init__(self, lam=1.0, lr=1e-2, n_iter=1000, tol=1e-6, verbose=False):\n",
    "        super().__init__()\n",
    "        self.lam = lam\n",
    "        self.lr = lr\n",
    "        self.n_iter = n_iter\n",
    "        self.tol = tol\n",
    "        self.verbose = verbose\n",
    "        self.loss_history = []\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        Xb = self._add_bias(X)\n",
    "        n, d = Xb.shape\n",
    "        w = np.zeros((d,1))\n",
    "        prev_loss = np.inf\n",
    "        for it in range(self.n_iter):\n",
    "            preds = Xb.dot(w)\n",
    "            err = preds - y\n",
    "            mse = (err**2).mean()\n",
    "            penalty = (self.lam / n) * (w[1:]**2).sum()\n",
    "            loss = mse + penalty\n",
    "            grad = 2.0 * Xb.T.dot(err) / n\n",
    "            grad[1:] += 2.0 * (self.lam / n) * w[1:]\n",
    "            w = w - self.lr * grad\n",
    "            self.loss_history.append(loss)\n",
    "            if self.verbose and it % (self.n_iter//10 + 1) == 0:\n",
    "                print(f'it {it}, loss {loss:.6f}')\n",
    "            if abs(prev_loss - loss) < self.tol:\n",
    "                break\n",
    "            prev_loss = loss\n",
    "        self.w = w\n",
    "        self.fitted = True\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05cf5a4",
   "metadata": {},
   "source": [
    "## 4. Оценка обобщающей способности\n",
    "Сравним: константную модель, аналитическую, GD и Ridge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2e7317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Блок 11: Константная модель\n",
    "class ConstantPredictor:\n",
    "    def __init__(self):\n",
    "        self.mu = None\n",
    "    def fit(self, y):\n",
    "        self.mu = y.mean()\n",
    "        return self\n",
    "    def predict(self, X):\n",
    "        return np.ones((X.shape[0],1)) * self.mu\n",
    "\n",
    "const = ConstantPredictor().fit(y_train)\n",
    "pred_const = const.predict(X_test_scaled)\n",
    "mse_const = mean_squared_error(y_test, pred_const)\n",
    "print('MSE constant:', mse_const)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3643ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Блок 12: Обучение всех моделей и сравнение\n",
    "models = {\n",
    "    'LinearAnalytic': LinearAnalytic().fit(X_train_scaled, y_train),\n",
    "    'LinearGD': LinearGD(lr=0.1, n_iter=5000, tol=1e-7).fit(X_train_scaled, y_train),\n",
    "    'RidgeAnalytic (lam=1.0)': RidgeAnalytic(lam=1.0).fit(X_train_scaled, y_train),\n",
    "    'RidgeGD (lam=1.0)': RidgeGD(lam=1.0, lr=0.1, n_iter=3000).fit(X_train_scaled, y_train)\n",
    "}\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    preds = model.predict(X_test_scaled)\n",
    "    mse = mean_squared_error(y_test, preds)\n",
    "    results[name] = mse\n",
    "\n",
    "results['Constant'] = mse_const\n",
    "\n",
    "print('\\nMSE на тесте:')\n",
    "for k,v in sorted(results.items(), key=lambda x: x[1]):\n",
    "    print(f'{k:30s}: {v:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d11617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Блок 13: Loss plots (для GD-моделей)\n",
    "plt.figure(figsize=(8,4))\n",
    "if hasattr(models['LinearGD'], 'loss_history'):\n",
    "    plt.plot(models['LinearGD'].loss_history, label='LinearGD')\n",
    "if hasattr(models['RidgeGD (lam=1.0)'], 'loss_history'):\n",
    "    plt.plot(models['RidgeGD (lam=1.0)'].loss_history, label='RidgeGD')\n",
    "plt.yscale('log')\n",
    "plt.xlabel('iters')\n",
    "plt.ylabel('loss (log)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e736c9a8",
   "metadata": {},
   "source": [
    "### Конец\n",
    "\n",
    "Файл сохранён в `/mnt/data/insurance_regression_notebook.ipynb`. Откройте и запустите ячейки. Если данные по другим путям — исправьте переменные `train_path`/`test_path`. "
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
